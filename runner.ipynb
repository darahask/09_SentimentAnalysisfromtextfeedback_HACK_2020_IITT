{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spresultaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_comments = pd.read_csv('D:/sentiment_analysis/dataset/gamma_dataset/maindata.csv')\n",
    "filter = toxic_comments[\"review\"] != \"\"\n",
    "toxic_comments = toxic_comments[filter]\n",
    "toxic_comments = toxic_comments.dropna()\n",
    "toxic_comments_labels = toxic_comments[['rating1','rating2','rating3','rating4','rating5']]\n",
    "\n",
    "X = []\n",
    "sentences = list(toxic_comments[\"review\"])\n",
    "for sen in sentences:\n",
    "    X.append(preprocess_text(sen))\n",
    "\n",
    "y = toxic_comments_labels.values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved_model._make_predict_function()\n",
    "graph = tf.get_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(fdb,tokenizer):\n",
    "    xp = [preprocess_text(fdb)]\n",
    "    x_trainp = np.array(xp)\n",
    "    x_trainp = tokenizer.texts_to_sequences(x_trainp)\n",
    "\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    maxlen = 200\n",
    "    x_trainp = pad_sequences(x_trainp, padding='post', maxlen=maxlen)\n",
    "    \n",
    "    global sess\n",
    "    global graph\n",
    "    with graph.as_default():\n",
    "        if 'sess' in locals() and sess is not None:\n",
    "            print('Close interactive session')\n",
    "            sess.close()\n",
    "        K.set_session(sess)\n",
    "        saved_model = tf.keras.models.load_model('new_run_cross')\n",
    "        result = saved_model.predict(x_trainp)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer(result):\n",
    "    l = list(chain.from_iterable(result))\n",
    "    ind = l.index(max(l))\n",
    "    val = ''\n",
    "    ind = ind+1\n",
    "    if(ind==1):\n",
    "        val = '128545'\n",
    "    \n",
    "    elif(ind==2):\n",
    "        val = '128577'\n",
    "    \n",
    "    elif(ind==3):\n",
    "        val = '128528'\n",
    "    \n",
    "    elif(ind==4):\n",
    "        val = '128578'\n",
    "    \n",
    "    else:\n",
    "        val = '128513'\n",
    "    \n",
    "    \n",
    "    return ind,val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "saved_model = tf.keras.models.load_model('nlp86')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [23/Jan/2020 11:13:35] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [23/Jan/2020 11:13:35] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def show() -> 'html':\n",
    "    return render_template('./page.html',the_title='feedback')\n",
    "\n",
    "@app.route('/feedback', methods=['POST'])\n",
    "def sentiment() -> 'html':\n",
    "    value = request.form['ta1'] + \" \" + request.form['ta2'] + \" \" + request.form['ta3'] + \" \" + request.form['ta4'] + \" \" + request.form['g']\n",
    "    prediction = predict(value,tokenizer)\n",
    "#     print(prediction)\n",
    "#     print(prediction.shape)\n",
    "#     print(len(prediction))\n",
    "    ind, val = scorer(prediction)\n",
    "    return render_template('./result.html',result = prediction,index = ind,emoji = val)\n",
    "\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
