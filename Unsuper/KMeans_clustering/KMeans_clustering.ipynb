{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = Word2Vec.load(\"../preprocessing_and_embeddings/word2vec4.model\").wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=2, max_iter=1000, random_state=True, n_init=50).fit(X=word_vectors.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 0.9726927876472473),\n",
       " ('_', 0.9710683226585388),\n",
       " ('5', 0.9659795761108398),\n",
       " ('6', 0.9639382362365723),\n",
       " ('0', 0.9605770111083984),\n",
       " ('8', 0.9574055671691895),\n",
       " ('2', 0.9568417072296143),\n",
       " ('7', 0.9274511337280273),\n",
       " ('9', 0.8446725606918335),\n",
       " ('x', 0.7778298258781433)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_vector(model.cluster_centers_[0], topn=10, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_cluster_center = model.cluster_centers_[0]\n",
    "negative_cluster_center = model.cluster_centers_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shruti priya\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "words = pd.DataFrame(word_vectors.vocab.keys())\n",
    "words.columns = ['words']\n",
    "words['vectors'] = words.words.apply(lambda x: word_vectors.wv[f'{x}'])\n",
    "words['cluster'] = words.vectors.apply(lambda x: model.predict([np.array(x)]))\n",
    "words.cluster = words.cluster.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "words['cluster_value'] = [1 if i==0 else -1 for i in words.cluster]\n",
    "words['closeness_score'] = words.apply(lambda x: 1/(model.transform([x.vectors]).min()), axis=1)\n",
    "words['sentiment_coeff'] = words.closeness_score * words.cluster_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>vectors</th>\n",
       "      <th>cluster</th>\n",
       "      <th>cluster_value</th>\n",
       "      <th>closeness_score</th>\n",
       "      <th>sentiment_coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>n</td>\n",
       "      <td>[-0.09285517, 0.07088268, 0.03835271, 0.082714...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.805886</td>\n",
       "      <td>-1.805886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>o</td>\n",
       "      <td>[0.00068575446, 0.005786211, 0.010378235, 0.05...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.216748</td>\n",
       "      <td>-2.216748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>[-0.050399292, 0.06851965, -0.025531558, 0.069...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.988305</td>\n",
       "      <td>-1.988305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>[0.028829122, -0.012237509, 0.042112265, 0.017...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.779262</td>\n",
       "      <td>-1.779262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>[0.013581241, 0.009512896, 0.026526261, 0.0737...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.657712</td>\n",
       "      <td>-1.657712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>u</td>\n",
       "      <td>[-0.120608084, 0.040273793, 0.008044605, 0.092...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.623003</td>\n",
       "      <td>-1.623003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>c</td>\n",
       "      <td>[-0.11271165, 0.15995622, 0.012432765, 0.13677...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.966052</td>\n",
       "      <td>-1.966052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>h</td>\n",
       "      <td>[0.04816323, 0.053908147, 0.023999557, 0.02569...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.958657</td>\n",
       "      <td>-1.958657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>w</td>\n",
       "      <td>[0.07316844, -0.06293852, -0.016908227, -0.064...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.740677</td>\n",
       "      <td>-1.740677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>r</td>\n",
       "      <td>[-0.016332058, 0.036741607, 0.04591001, 0.0658...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.962069</td>\n",
       "      <td>-1.962069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  words                                            vectors  cluster  \\\n",
       "0     n  [-0.09285517, 0.07088268, 0.03835271, 0.082714...        1   \n",
       "1     o  [0.00068575446, 0.005786211, 0.010378235, 0.05...        1   \n",
       "2     t  [-0.050399292, 0.06851965, -0.025531558, 0.069...        1   \n",
       "3        [0.028829122, -0.012237509, 0.042112265, 0.017...        1   \n",
       "4     m  [0.013581241, 0.009512896, 0.026526261, 0.0737...        1   \n",
       "5     u  [-0.120608084, 0.040273793, 0.008044605, 0.092...        1   \n",
       "6     c  [-0.11271165, 0.15995622, 0.012432765, 0.13677...        1   \n",
       "7     h  [0.04816323, 0.053908147, 0.023999557, 0.02569...        1   \n",
       "8     w  [0.07316844, -0.06293852, -0.016908227, -0.064...        1   \n",
       "9     r  [-0.016332058, 0.036741607, 0.04591001, 0.0658...        1   \n",
       "\n",
       "   cluster_value  closeness_score  sentiment_coeff  \n",
       "0             -1         1.805886        -1.805886  \n",
       "1             -1         2.216748        -2.216748  \n",
       "2             -1         1.988305        -1.988305  \n",
       "3             -1         1.779262        -1.779262  \n",
       "4             -1         1.657712        -1.657712  \n",
       "5             -1         1.623003        -1.623003  \n",
       "6             -1         1.966052        -1.966052  \n",
       "7             -1         1.958657        -1.958657  \n",
       "8             -1         1.740677        -1.740677  \n",
       "9             -1         1.962069        -1.962069  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[['words', 'sentiment_coeff']].to_csv('sentiment_dictionary4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
